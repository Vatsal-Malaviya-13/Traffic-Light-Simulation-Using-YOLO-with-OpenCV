{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countVeh(img):\n",
    "    height, width, channels = img.shape\n",
    "    # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                if class_id != 0:\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    #Visualizing CCTV Footage Vehicle Detection\n",
    "    #font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "            #cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return len(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeCount(cnt):\n",
    "    cnt[cnt[:] < 3] = 3\n",
    "    cnt[cnt[:] > 30 ] =30\n",
    "    y = 3 * cnt\n",
    "    stop_time = np.zeros((len(cnt),1))\n",
    "    stop_time[0] = np.sum(y) - y[0]\n",
    "    for i in range(1,len(cnt)):\n",
    "        stop_time[i]=stop_time[i-1]-y[i]\n",
    "    return stop_time,cnt,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle Count \n",
      "[22.  7. 16. 11.]\n",
      "Green/Go Time \n",
      "[66. 21. 48. 33.]\n",
      "Stop Time \n",
      "[[102.]\n",
      " [ 81.]\n",
      " [ 33.]\n",
      " [  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Simple Examples Similar to a Cross-Section Representing CCTV Footage like Photos taken ON Indian Roads\n",
    "c = np.zeros(4)\n",
    "img1 = cv2.imread(\"test1.jfif\")\n",
    "img1 = cv2.resize(img1, None, fx=2, fy=2)\n",
    "c[0] = countVeh(img1)\n",
    "img2 = cv2.imread(\"test2.webp\")\n",
    "img2 = cv2.resize(img2, None, fx=1, fy=1)\n",
    "c[1] = countVeh(img2)\n",
    "img3 = cv2.imread(\"test3.jpg\")\n",
    "img3 = cv2.resize(img3, None, fx=0.8, fy=0.8)\n",
    "c[2] = countVeh(img3)\n",
    "img4 = cv2.imread(\"test4.jpg\")\n",
    "img4 = cv2.resize(img4, None, fx=0.6, fy=0.6)\n",
    "c[3] = countVeh(img4)\n",
    "stop_time,cnt,go_time = timeCount(c)\n",
    "print(\"Vehicle Count \\n\" + str(cnt))\n",
    "print(\"Green/Go Time \\n\" + str(go_time))\n",
    "print(\"Stop Time \\n\" + str(stop_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
